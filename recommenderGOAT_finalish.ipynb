{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fx3kGumAs5EU",
        "outputId": "faa5ff42-3883-4f0e-a5c6-1f0d889d63a3"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "6CKcL0n8N4NT"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "pd.set_option(\"display.precision\", 1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(nrows=100000):\n",
        "\n",
        "    # Load training data using pandas with a limit on the number of rows\n",
        "    item_train_df = pd.read_csv('./drive/MyDrive/final_item_features.csv', nrows=nrows, dtype={'column_name': 'float32'})\n",
        "    user_train_df = pd.read_csv('./drive/MyDrive/final_user_features.csv', nrows=nrows, dtype={'column_name': 'float32'})\n",
        "    y_train_df = pd.read_csv('./drive/MyDrive/y_train.csv', nrows=nrows, dtype={'column_name': 'float32'})\n",
        "\n",
        "    # Handle NaN values by replacing them with 0\n",
        "    user_train_df.fillna(0, inplace=True)\n",
        "    item_train_df.fillna(0, inplace=True)\n",
        "    y_train_df.fillna(0, inplace=True)\n",
        "\n",
        "    # Convert all columns except the first one to numeric\n",
        "    item_train_df = item_train_df.apply(pd.to_numeric, errors='coerce')\n",
        "    user_train_df = user_train_df.apply(pd.to_numeric, errors='coerce')\n",
        "\n",
        "    return item_train_df, user_train_df, y_train_df\n",
        "\n",
        "item_train_df, user_train_df, y_train_df = load_data()\n",
        "num_user_features = user_train_df.shape[1]\n",
        "num_item_features = item_train_df.shape[1]\n",
        "\n",
        "# Handle NaN values by replacing them with 0 (again)\n",
        "user_train_df.fillna(0, inplace=True)\n",
        "item_train_df.fillna(0, inplace=True)\n",
        "y_train_df.fillna(0, inplace=True)\n",
        "\n",
        "# Print out shapes and samples to inspect the data\n",
        "print(f\"User Training Data Shape: {user_train_df.shape}\")\n",
        "print(f\"Item Training Data Shape: {item_train_df.shape}\")\n",
        "print(f\"y_train Shape: {y_train_df.shape}\")\n",
        "\n",
        "# Display sample data\n",
        "print(\"Sample User Features (first 5):\")\n",
        "print(user_train_df.head())\n",
        "print(\"Sample Item Features (first 5):\")\n",
        "print(item_train_df.head())\n",
        "print(\"Sample Ratings (first 5):\")\n",
        "print(y_train_df.head())"
      ],
      "metadata": {
        "id": "lMH9HCtLN7GW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47905133-249c-42e5-bb5f-945aff618aa3"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-633dda195d32>:4: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  item_train_df = pd.read_csv('./drive/MyDrive/final_item_features.csv', nrows=nrows, dtype={'column_name': 'float32'})\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "User Training Data Shape: (100000, 31)\n",
            "Item Training Data Shape: (100000, 35)\n",
            "y_train Shape: (100000, 3)\n",
            "Sample User Features (first 5):\n",
            "   rating_count  rating_average  Mexican  Chinese  Italian  Irish  Pizza  \\\n",
            "0             3             2.7      0.0      0.0      0.0    0.0    4.0   \n",
            "1             3             2.7      0.0      0.0      0.0    0.0    4.0   \n",
            "2             3             2.7      0.0      0.0      0.0    0.0    4.0   \n",
            "3            31             4.3      4.2      4.0      4.5    3.0    4.0   \n",
            "4            31             4.3      4.2      4.0      4.5    3.0    4.0   \n",
            "\n",
            "   Bars  Nightlife  Japanese  ...  Ambience_classy  Ambience_trendy  \\\n",
            "0   2.5        2.5       0.0  ...              4.0              0.0   \n",
            "1   2.5        2.5       0.0  ...              4.0              0.0   \n",
            "2   2.5        2.5       0.0  ...              4.0              0.0   \n",
            "3   4.1        4.2       0.0  ...              4.8              4.7   \n",
            "4   4.1        4.2       0.0  ...              4.8              4.7   \n",
            "\n",
            "   Ambience_upscale  Ambience_casual  Alcohol  NoiseLevel  RestaurantsAttire  \\\n",
            "0               0.0              2.7        0           0                  0   \n",
            "1               0.0              2.7        0           0                  0   \n",
            "2               0.0              2.7        0           0                  0   \n",
            "3               0.0              4.2        0           0                  0   \n",
            "4               0.0              4.2        0           0                  0   \n",
            "\n",
            "   RestaurantsPriceRange2  HasTV  GoodForGroups  \n",
            "0                     1.7    1.0            1.0  \n",
            "1                     1.7    1.0            1.0  \n",
            "2                     1.7    1.0            1.0  \n",
            "3                     1.8    0.9            1.0  \n",
            "4                     1.8    0.9            1.0  \n",
            "\n",
            "[5 rows x 31 columns]\n",
            "Sample Item Features (first 5):\n",
            "   stars  review_count  RestaurantsPriceRange2  WiFi  alcohol  NoiseLevel  \\\n",
            "0    4.0           164                     2.0     0        2         0.0   \n",
            "1    3.0           347                     2.0     1        2         2.0   \n",
            "2    4.5           114                     1.0     1        0         2.0   \n",
            "3    3.5            47                     1.0     1        0         2.0   \n",
            "4    3.5          1112                     2.0     1        1         2.0   \n",
            "\n",
            "   RestaurantsGoodForGroups  GoodForKids  HasTV  attire  ...  Irish  Japanese  \\\n",
            "0                         1            0      1     0.0  ...      0         0   \n",
            "1                         1            1      1     0.0  ...      0         0   \n",
            "2                         1            1      1     0.0  ...      0         0   \n",
            "3                         1            1      1     0.0  ...      0         0   \n",
            "4                         1            1      0     0.0  ...      0         0   \n",
            "\n",
            "   Thai  Pizza  Seafood  Sandwiches  Steakhouses  Burgers  Bars  Indian  \n",
            "0     0      1        0           0            0        0     1       0  \n",
            "1     0      0        0           1            0        0     1       0  \n",
            "2     0      0        0           1            0        0     0       0  \n",
            "3     0      0        0           0            0        0     0       0  \n",
            "4     1      0        0           0            0        0     0       0  \n",
            "\n",
            "[5 rows x 35 columns]\n",
            "Sample Ratings (first 5):\n",
            "                  user_id             business_id  rating\n",
            "0  OyoGAe7OKpv6SyGZT5g77Q  FlhLKsuV-QuLBzn1XFLvaA     4.0\n",
            "1  OyoGAe7OKpv6SyGZT5g77Q  cwn_MBPFUJtme68WURSgKA     1.0\n",
            "2  OyoGAe7OKpv6SyGZT5g77Q  5E0cBlMLwwDwOrtyAYM6dw     3.0\n",
            "3  8g_iMtfSiwikVnbP2etR0A  YjUWPpI6HXG530lwP-fb2A     3.0\n",
            "4  8g_iMtfSiwikVnbP2etR0A  eaDZlSuVS0EY67Ke6pRP6Q     4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_training_data(user_train_df, item_train_df, y_train_df):\n",
        "\n",
        "    # Convert DataFrames to NumPy arrays\n",
        "    user_train = user_train_df.to_numpy()\n",
        "    item_train = item_train_df.to_numpy()\n",
        "    y_train = y_train_df.iloc[:, 2].to_numpy()\n",
        "\n",
        "    # Reshape y_train to be a column vector\n",
        "    y_train = y_train.reshape(-1, 1)\n",
        "\n",
        "    return user_train, item_train, y_train\n",
        "\n",
        "user_train, item_train, y_train = prepare_training_data(user_train_df, item_train_df, y_train_df)\n",
        "\n",
        "# Print out shapes of the prepared training data\n",
        "print(\"Converted User Training Data Shape:\", user_train.shape)\n",
        "print(\"Converted Item Training Data Shape:\", item_train.shape)\n",
        "print(\"Converted Ratings Shape:\", y_train.shape)\n",
        "print(\"Converted Item Training Data Shape:\", item_train)"
      ],
      "metadata": {
        "id": "U-iq3AKcN9tG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd8319df-b87f-44e5-83a5-e39b5644208c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converted User Training Data Shape: (100000, 31)\n",
            "Converted Item Training Data Shape: (100000, 35)\n",
            "Converted Ratings Shape: (100000, 1)\n",
            "Converted Item Training Data Shape: [[  4.  164.    2.  ...   0.    1.    0. ]\n",
            " [  3.  347.    2.  ...   0.    1.    0. ]\n",
            " [  4.5 114.    1.  ...   0.    0.    0. ]\n",
            " ...\n",
            " [  4.5 139.    2.  ...   0.    0.    0. ]\n",
            " [  4.  171.    1.  ...   0.    0.    0. ]\n",
            " [  4.5  43.    2.  ...   0.    0.    0. ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure all data is in float format\n",
        "item_train = item_train.astype(np.float32)\n",
        "user_train = user_train.astype(np.float32)\n",
        "y_train = y_train.astype(np.float32)\n",
        "\n",
        "# Scale data\n",
        "item_train_unscaled = item_train.copy()\n",
        "user_train_unscaled = user_train.copy()\n",
        "y_train_unscaled = y_train.copy()\n",
        "\n",
        "scalerItem = StandardScaler()\n",
        "scalerUser = StandardScaler()\n",
        "scalerTarget = MinMaxScaler((-1, 1))\n",
        "\n",
        "item_train = scalerItem.fit_transform(item_train)\n",
        "user_train = scalerUser.fit_transform(user_train)\n",
        "y_train = scalerTarget.fit_transform(y_train.reshape(-1, 1)).flatten()"
      ],
      "metadata": {
        "id": "hUxfx_s7N-7E"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train-Test Split\n",
        "user_train, user_test = train_test_split(user_train, train_size=0.7, shuffle=True, random_state=1)\n",
        "item_train, item_test = train_test_split(item_train, train_size=0.7, shuffle=True, random_state=1)\n",
        "y_train, y_test = train_test_split(y_train, train_size=0.7, shuffle=True, random_state=1)\n",
        "\n",
        "print(f\"User training data shape: {user_train.shape}\")\n",
        "print(f\"Item (Restaurant) training data shape: {item_train.shape}\")"
      ],
      "metadata": {
        "id": "dKPQPz0yN_bq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "589d2865-874e-458b-a974-23707ad02949"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "User training data shape: (70000, 31)\n",
            "Item (Restaurant) training data shape: (70000, 35)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define Neural Network Models\n",
        "class UserNN(nn.Module):\n",
        "    def __init__(self, num_user_features, num_outputs):\n",
        "        super(UserNN, self).__init__()\n",
        "        self.fc1 = nn.Linear(num_user_features, 256)\n",
        "        self.fc2 = nn.Linear(256, 128)\n",
        "        self.fc3 = nn.Linear(128, num_outputs)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        return self.fc3(x)\n",
        "\n",
        "class ItemNN(nn.Module):\n",
        "    def __init__(self, num_item_features, num_outputs):\n",
        "        super(ItemNN, self).__init__()\n",
        "        self.fc1 = nn.Linear(num_item_features, 256)\n",
        "        self.fc2 = nn.Linear(256, 128)\n",
        "        self.fc3 = nn.Linear(128, num_outputs)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        return self.fc3(x)"
      ],
      "metadata": {
        "id": "9QUH78B3OBmj"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\")\n",
        "\n",
        "# Instantiate models with half precision\n",
        "num_outputs = 64  # Embedding size\n",
        "user_nn = UserNN(num_user_features, num_outputs).to(device).half()\n",
        "item_nn = ItemNN(num_item_features, num_outputs).to(device).half()\n",
        "\n",
        "# Create inputs in half precision and move them to GPU\n",
        "input_user = torch.tensor(user_train, dtype=torch.float16).to(device)\n",
        "input_item = torch.tensor(item_train, dtype=torch.float16).to(device)\n",
        "\n",
        "# Forward pass through user and item networks\n",
        "vu = user_nn(input_user)\n",
        "vu = nn.functional.normalize(vu, dim=1)\n",
        "\n",
        "vm = item_nn(input_item)\n",
        "vm = nn.functional.normalize(vm, dim=1)\n",
        "\n",
        "# Define a smaller batch size to avoid memory issues\n",
        "batch_size = 64\n",
        "\n",
        "# Keep the output tensor on CPU to save GPU memory\n",
        "output = torch.zeros(input_user.shape[0], item_train.shape[0], dtype=torch.float16)\n",
        "\n",
        "# Mini-batch processing\n",
        "for start in range(0, input_user.shape[0], batch_size):\n",
        "    end = start + batch_size\n",
        "    user_batch = vu[start:end].to(device)\n",
        "\n",
        "    # Compute the scores for this batch in float16\n",
        "    batch_output = torch.mm(user_batch, vm.t())\n",
        "\n",
        "    # Move the batch output back to CPU and store in the output tensor\n",
        "    output[start:end] = batch_output.cpu()\n",
        "\n",
        "# Now `output` contains the predicted scores for all users and items on the CPU in float16"
      ],
      "metadata": {
        "id": "hAbZgJm6OCqM"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine Models into a Recommendation Model\n",
        "class RecommendationModel(nn.Module):\n",
        "    def __init__(self, user_nn, item_nn):\n",
        "        super(RecommendationModel, self).__init__()\n",
        "        self.user_nn = user_nn\n",
        "        self.item_nn = item_nn\n",
        "\n",
        "    def forward(self, user_input, item_input):\n",
        "        vu = self.user_nn(user_input)\n",
        "        vu = nn.functional.normalize(vu, dim=1)\n",
        "        vm = self.item_nn(item_input)\n",
        "        vm = nn.functional.normalize(vm, dim=1)\n",
        "        output = torch.bmm(vu.unsqueeze(1), vm.unsqueeze(2)).squeeze()\n",
        "        return output\n",
        "\n",
        "model = RecommendationModel(user_nn, item_nn)\n",
        "print(model)"
      ],
      "metadata": {
        "id": "B7NP5mHSOD-E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba4d96a6-c8a9-4de4-ea30-575b87371c8f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RecommendationModel(\n",
            "  (user_nn): UserNN(\n",
            "    (fc1): Linear(in_features=31, out_features=256, bias=True)\n",
            "    (fc2): Linear(in_features=256, out_features=128, bias=True)\n",
            "    (fc3): Linear(in_features=128, out_features=64, bias=True)\n",
            "  )\n",
            "  (item_nn): ItemNN(\n",
            "    (fc1): Linear(in_features=35, out_features=256, bias=True)\n",
            "    (fc2): Linear(in_features=256, out_features=128, bias=True)\n",
            "    (fc3): Linear(in_features=128, out_features=64, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set random seed for reproducibility\n",
        "torch.manual_seed(1)\n",
        "\n",
        "# Define loss function and optimizer\n",
        "cost_fn = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)"
      ],
      "metadata": {
        "id": "RQiRoeBbOGFr"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the Model\n",
        "num_epochs = 170\n",
        "\n",
        "model = model.to(device).float()\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Prepare data and move to the same device as the model\n",
        "    user_batch = torch.tensor(user_train, dtype=torch.float32).to(device)\n",
        "    item_batch = torch.tensor(item_train, dtype=torch.float32).to(device)\n",
        "    y_batch = torch.tensor(y_train, dtype=torch.float32).squeeze().to(device)\n",
        "\n",
        "    # Forward pass\n",
        "    predictions = model(user_batch, item_batch)\n",
        "\n",
        "    # Compute loss\n",
        "    loss = cost_fn(predictions, y_batch)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if (epoch + 1) % 5 == 0:\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')"
      ],
      "metadata": {
        "id": "uXgHlGQIOGYu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b139c803-cf10-4820-8c50-3a7529ce7688"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [5/170], Loss: 0.3151\n",
            "Epoch [10/170], Loss: 0.3028\n",
            "Epoch [15/170], Loss: 0.3070\n",
            "Epoch [20/170], Loss: 0.2859\n",
            "Epoch [25/170], Loss: 0.2765\n",
            "Epoch [30/170], Loss: 0.2716\n",
            "Epoch [35/170], Loss: 0.2623\n",
            "Epoch [40/170], Loss: 0.2508\n",
            "Epoch [45/170], Loss: 0.2424\n",
            "Epoch [50/170], Loss: 0.2373\n",
            "Epoch [55/170], Loss: 0.2347\n",
            "Epoch [60/170], Loss: 0.2323\n",
            "Epoch [65/170], Loss: 0.2303\n",
            "Epoch [70/170], Loss: 0.2289\n",
            "Epoch [75/170], Loss: 0.2276\n",
            "Epoch [80/170], Loss: 0.2266\n",
            "Epoch [85/170], Loss: 0.2256\n",
            "Epoch [90/170], Loss: 0.2248\n",
            "Epoch [95/170], Loss: 0.2241\n",
            "Epoch [100/170], Loss: 0.2234\n",
            "Epoch [105/170], Loss: 0.2228\n",
            "Epoch [110/170], Loss: 0.2223\n",
            "Epoch [115/170], Loss: 0.2217\n",
            "Epoch [120/170], Loss: 0.2212\n",
            "Epoch [125/170], Loss: 0.2207\n",
            "Epoch [130/170], Loss: 0.2202\n",
            "Epoch [135/170], Loss: 0.2198\n",
            "Epoch [140/170], Loss: 0.2193\n",
            "Epoch [145/170], Loss: 0.2188\n",
            "Epoch [150/170], Loss: 0.2183\n",
            "Epoch [155/170], Loss: 0.2177\n",
            "Epoch [160/170], Loss: 0.2172\n",
            "Epoch [165/170], Loss: 0.2167\n",
            "Epoch [170/170], Loss: 0.2161\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the Model\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    user_test_tensor = torch.tensor(user_test, dtype=torch.float32).to(device)\n",
        "    item_test_tensor = torch.tensor(item_test, dtype=torch.float32).to(device)\n",
        "    y_test_tensor = torch.tensor(y_test, dtype=torch.float32).squeeze().to(device)\n",
        "\n",
        "    # Make predictions\n",
        "    test_predictions = model(user_test_tensor, item_test_tensor)\n",
        "\n",
        "    # Compute test loss\n",
        "    test_loss = cost_fn(test_predictions, y_test_tensor)\n",
        "    print(f'Test Loss: {test_loss.item():.4f}')"
      ],
      "metadata": {
        "id": "lBODXZ-JOPb5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f0410d4-a7ba-4d83-dac7-84d38887e0a5"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.2283\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the Model Weights\n",
        "model_path = 'model_weights.pth'\n",
        "torch.save(model.state_dict(), model_path)\n",
        "print(f'Model weights saved to {model_path}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dv1XTgwHkhn9",
        "outputId": "195e97fb-1558-4272-9dbf-e7d32913e6d3"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model weights saved to model_weights.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example: New user\n",
        "new_user = np.array([[3, 4.0, 4.0, 0.0, 0.0, 0.0, 0.0, 4.0, 4.0, 0.0, 0.0, 4.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 4.0, 0, 0, 0, 2.0, 0.6666666666666666, 0.6666666666666666]])  # Modify based on relevant features\n",
        "new_user_scaled = scalerUser.transform(new_user)\n",
        "\n",
        "# Convert to tensor and predict\n",
        "new_user_tensor = torch.tensor(new_user_scaled, dtype=torch.float32).to(device)\n",
        "\n",
        "# Get all item features and convert to tensor\n",
        "item_tensor = torch.tensor(item_train, dtype=torch.float32).to(device)\n",
        "\n",
        "# Repeat new user tensor for all items to create the correct input shape\n",
        "new_user_batch = new_user_tensor.repeat(item_tensor.shape[0], 1)\n",
        "\n",
        "# Make predictions for all items\n",
        "predictions = model(new_user_batch, item_tensor)\n",
        "\n",
        "# Inverse scale and show top 10 recommendations\n",
        "predictions_inverse = scalerTarget.inverse_transform(predictions.reshape(-1, 1).detach().cpu().numpy())\n",
        "top_10_indices = predictions_inverse.flatten().argsort()[-10:][::-1]\n",
        "\n",
        "print(\"Top 10 Restaurant Recommendations for New User:\")\n",
        "print(item_train_df.iloc[top_10_indices])\n"
      ],
      "metadata": {
        "id": "XQm6fu49OTDB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65e0f3ef-d046-473e-f4c4-2de0abab88d2"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 10 Restaurant Recommendations for New User:\n",
            "       stars  review_count  RestaurantsPriceRange2  WiFi  alcohol  NoiseLevel  \\\n",
            "32397    4.5           230                     2.0     0        0         1.0   \n",
            "30846    4.5           183                     2.0     1        1         2.0   \n",
            "24693    3.5            51                     3.0     0        2         2.0   \n",
            "25008    4.0           161                     2.0     1        2         2.0   \n",
            "455      4.0           371                     1.0     1        0         2.0   \n",
            "32371    4.0            30                     1.0     0        0         1.0   \n",
            "16962    4.5            25                     1.0     0        0         2.0   \n",
            "65533    2.0            36                     1.0     0        0         2.0   \n",
            "52470    3.5           165                     3.0     1        2         2.0   \n",
            "14510    3.5             6                     1.0     0        0         0.0   \n",
            "\n",
            "       RestaurantsGoodForGroups  GoodForKids  HasTV  attire  ...  Irish  \\\n",
            "32397                         1            1      0     0.0  ...      0   \n",
            "30846                         1            1      1     0.0  ...      0   \n",
            "24693                         1            1      1     0.0  ...      0   \n",
            "25008                         1            0      0     0.0  ...      0   \n",
            "455                           0            1      1     0.0  ...      0   \n",
            "32371                         1            1      0     0.0  ...      0   \n",
            "16962                         0            1      1     0.0  ...      0   \n",
            "65533                         0            1      1     0.0  ...      0   \n",
            "52470                         1            0      1     1.0  ...      0   \n",
            "14510                         0            0      0     0.0  ...      0   \n",
            "\n",
            "       Japanese  Thai  Pizza  Seafood  Sandwiches  Steakhouses  Burgers  Bars  \\\n",
            "32397         0     0      0        0           0            0        0     0   \n",
            "30846         0     0      0        0           1            0        0     0   \n",
            "24693         0     0      0        0           0            0        0     1   \n",
            "25008         0     0      0        0           0            0        0     1   \n",
            "455           0     0      0        0           0            0        0     0   \n",
            "32371         0     0      0        0           0            0        0     0   \n",
            "16962         0     0      0        0           0            0        0     0   \n",
            "65533         0     0      1        0           0            0        0     0   \n",
            "52470         0     0      0        0           0            0        0     0   \n",
            "14510         0     0      0        0           0            0        0     0   \n",
            "\n",
            "       Indian  \n",
            "32397       0  \n",
            "30846       0  \n",
            "24693       0  \n",
            "25008       0  \n",
            "455         0  \n",
            "32371       0  \n",
            "16962       0  \n",
            "65533       0  \n",
            "52470       0  \n",
            "14510       0  \n",
            "\n",
            "[10 rows x 35 columns]\n"
          ]
        }
      ]
    }
  ]
}